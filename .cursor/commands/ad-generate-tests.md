{
  "name": "AD Generate Tests",
  "command": "ad generate tests",
  "prompt": "You are generating tests following the Accelerated Delivery Framework testing pyramid.\n\n---\n\n### STEP 1: Identify What to Test\n\nAsk the user or identify:\n- What feature/service/component needs tests?\n- What type of tests are needed? (unit/integration/E2E)\n- What methods/endpoints/flows need coverage?\n\n---\n\n### STEP 2: Review Testing Strategy\n\n1. Read `docs/TEST_AUTOMATION_STRATEGY.md`:\n   - Understand testing pyramid (60% unit, 30% integration, 10% E2E)\n   - Review test patterns and conventions\n   - Check coverage thresholds\n\n2. Review existing tests:\n   - Find similar test files\n   - Understand test patterns used\n   - Note: Setup, mocking, assertions, naming conventions\n\n3. Review the code to test:\n   - Understand all public methods\n   - Identify dependencies to mock\n   - Understand expected behavior\n\n---\n\n### STEP 3: Determine Test Type\n\nBased on what needs testing:\n\n**Unit Tests** (60%):\n- Pure business logic\n- Service layer methods\n- Calculations, transformations\n- All dependencies mocked\n\n**Integration Tests** (30%):\n- API endpoints\n- Database interactions\n- Service + Repository integration\n- External APIs mocked, database real\n\n**E2E Tests** (10%):\n- Critical user journeys\n- Complete flows\n- UI interactions\n- Nothing mocked\n\n---\n\n### STEP 4: Generate Tests\n\n#### For Unit Tests:\n\n```\nTask: Generate unit tests for [ServiceName]\n\nContext:\n1. Review TEST_AUTOMATION_STRATEGY.md for our testing approach\n2. Look at existing tests (e.g., [SimilarTestFile]) for patterns\n3. Review the service to understand all methods\n\nRequirements:\n- Test all public methods\n- Cover happy path and error cases\n- Mock all dependencies ([list dependencies])\n- Follow [xUnit/Jasmine/Jest] conventions\n- Use Theory/InlineData for parameterized tests\n- Assert on return values and mock interactions\n\nGenerate:\n- Test class with proper setup (constructor, mocks)\n- At least 3 test cases per public method\n- Use descriptive test names (MethodName_Scenario_ExpectedResult)\n```\n\n#### For Integration Tests:\n\n```\nTask: Generate integration tests for [ControllerName]\n\nContext:\n1. Review how we use WebApplicationFactory\n2. Look at existing integration tests\n3. Review our API response pattern (success/error format)\n\nRequirements:\n- Test all CRUD endpoints\n- Use in-memory database\n- Test both success and error scenarios\n- Verify HTTP status codes\n- Verify response structure\n- Clean up data between tests\n\nGenerate:\n- Test class inheriting from our base integration test class\n- Tests for GET, POST, PUT, DELETE\n- Negative test cases (not found, validation errors)\n```\n\n#### For E2E Tests:\n\n```\nTask: Generate E2E test for [feature] flow\n\nContext:\n1. Review MANUAL_REGRESSION_TESTING.md for user flows\n2. Look at existing Playwright tests\n3. Understand our authentication flow\n\nRequirements:\n- Test complete flow: [list steps]\n- Use Page Object Model\n- Handle authentication state\n- Take screenshots on failure\n- Use descriptive test names\n\nGenerate:\n- Page object for [page]\n- E2E test covering the full flow\n- Proper assertions at each step\n```\n\n---\n\n### STEP 5: Verify Coverage\n\nAfter generating tests:\n\n1. Check coverage:\n   - Unit tests: Aim for 80% coverage for service layer\n   - Integration tests: All endpoints covered\n   - E2E tests: Critical flows covered\n\n2. Identify gaps:\n   - List untested public methods\n   - List endpoints without integration tests\n   - List critical flows without E2E tests\n\n3. Generate additional tests if needed\n\n---\n\n### STEP 6: Verify Tests Pass\n\n1. Run tests\n2. Fix any failures\n3. Ensure all tests pass\n4. Verify coverage thresholds met\n\n---\n\n### OUTPUT FORMAT\n\nAfter generating tests:\n\n```\n## Test Generation Complete\n\n‚úÖ Tests Generated:\n- Unit tests: [count] tests in [file]\n- Integration tests: [count] tests in [file]\n- E2E tests: [count] tests in [file]\n\n‚úÖ Coverage:\n- Service layer: [X]%\n- Endpoints: [X]/[Y] covered\n- Critical flows: [X]/[Y] covered\n\nüìã Test Files:\n- [List of test files created]\n\n‚úÖ All tests pass: ‚úÖ/‚ùå\n```\n\n---\n\n**Important Notes:**\n- Always review TEST_AUTOMATION_STRATEGY.md first\n- Follow existing test patterns\n- Mock all dependencies for unit tests\n- Use real database for integration tests\n- Generate tests per testing pyramid (60/30/10)\n- Verify coverage thresholds\n- Reference: `docs/ai-pod/common/accelerated-delivery-framework.md` (lines 419-551)"
}
